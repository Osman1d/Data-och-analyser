duckdb
streamlit
# duckdb
*.wal
*.DS_Store
# dbeaver
.dbeaver
.project
# rådata
raw_data/
# backend/rename_files.py
import os

def rename_files(raw_data_dir="raw_data"):
    """Rensar filnamn i raw_data genom att behålla första delen av namnet."""
    for filename in os.listdir(raw_data_dir):
        if " " in filename:
            new_name = filename.split()[0] + ".csv"  # Behåller första delen och lägger till .csv
            os.rename(
                os.path.join(raw_data_dir, filename),
                os.path.join(raw_data_dir, new_name)
            )
    print(f"Rensat filnamn i {raw_data_dir}.")

if __name__ == "__main__":
    os.makedirs("raw_data", exist_ok=True)
    # Skapa exempeldata för test
    open("raw_data/Enhetstyp 2024-08-13_2024-09-10 AIgineer.csv", "w").close()
    open("raw_data/KPI 2024-08-13_2024-09-10 AIgineer.csv", "w").close()
    rename_files()
    # backend/load_to_db.py
import os
import duckdb
import csv

def load_to_db(raw_data_dir="raw_data", db_file="youtube_analytics.db"):
    """Laddar CSV-filer från raw_data till en DuckDB-databas."""
    conn = duckdb.connect(db_file)
    for filename in os.listdir(raw_data_dir):
        table_name = filename.split(".")[0]
        file_path = os.path.join(raw_data_dir, filename)
        # Läs CSV och skapa tabell
        with open(file_path, "r") as f:
            reader = csv.reader(f)
            headers = next(reader)  # Första raden är rubriker
            # Skapa tabell med headers
            columns = ", ".join([f"{col} VARCHAR" for col in headers])
            conn.execute(f"CREATE OR REPLACE TABLE {table_name} ({columns})")
            # Lägg till rader
            for row in reader:
                placeholders = ", ".join(["?" for _ in row])
                conn.execute(f"INSERT INTO {table_name} VALUES ({placeholders})", row)
    conn.close()
    print(f"Laddat data från {raw_data_dir} till {db_file}.")

if __name__ == "__main__":
    load_to_db()
    -- backend/sql/eda.sql
-- EDA för att förstå databasen

-- Antal rader per tabell
SELECT 'Enhetstyp' AS table_name, COUNT(*) AS row_count FROM Enhetstyp
UNION ALL
SELECT 'KPI' AS table_name, COUNT(*) AS row_count FROM KPI;

-- Unika enhetstyper och deras förekomst
SELECT device_type, COUNT(*) AS count
FROM Enhetstyp
GROUP BY device_type;

-- Totala visningar per datum
SELECT date, SUM(CAST(views AS INTEGER)) AS total_views
FROM KPI
GROUP BY date
ORDER BY date;
# frontend/dashboard.py
import streamlit as st
import duckdb

class YouTubeDashboard:
    """Klass för att hantera YouTube Analytics-dashboarden."""
    def __init__(self, db_file="youtube_analytics.db"):
        self.conn = duckdb.connect(db_file)
    
    def fetch_data(self, query):
        """Hämta data från databasen."""
        return self.conn.execute(query).fetch_df()
    
    def display_kpi(self, title, value):
        """Visa en KPI i Streamlit."""
        st.metric(title, value)
    
    def run(self):
        """Kör dashboarden i Streamlit."""
        st.title("YouTube Analytics Dashboard")
        
        # KPI:er
        st.subheader("Key Performance Indicators")
        enhetstyp_data = self.fetch_data("SELECT * FROM Enhetstyp")
        kpi_data = self.fetch_data("SELECT * FROM KPI")
        total_views = sum(int(row["views"]) for _, row in kpi_data.iterrows())
        avg_views_per_device = total_views / len(enhetstyp_data) if len(enhetstyp_data) > 0 else 0
        unique_devices = len(enhetstyp_data["device_type"].unique())
        col1, col2, col3 = st.columns(3)
        with col1:
            self.display_kpi("Totala visningar", total_views)
        with col2:
            self.display_kpi("Genomsnittliga visningar per enhet", f"{avg_views_per_device:.2f}")
        with col3:
            self.display_kpi("Antal unika enhetstyper", unique_devices)
        
        # Filtrering
        st.subheader("Filtrera data")
        device_filter = st.selectbox("Välj enhetstyp", ["Alla"] + list(enhetstyp_data["device_type"].unique()))
        if device_filter != "Alla":
            filtered_data = self.fetch_data(f"SELECT * FROM KPI WHERE device_type = '{device_filter}'")
        else:
            filtered_data = kpi_data
        st.write("Filtrerad data (första 5 rader):", filtered_data.head())
        
        # Extra feature: Trendanalys
        st.subheader("Trend: Visningar per dag")
        trend_data = self.fetch_data("SELECT date, SUM(CAST(views AS INTEGER)) AS total_views FROM KPI GROUP BY date ORDER BY date")
        st.line_chart(trend_data.set_index("date"))

if __name__ == "__main__":
    dashboard = YouTubeDashboard()
    dashboard.run()
    # YouTube Analytics Dashboard

## Översikt
Detta projekt är en fullstackdashboard för att analysera YouTube-data med DuckDB och Streamlit.  
Syftet är att undersöka data och definiera egna KPI:er för datadrivna beslut.

## Installation
1. Klona kursrepot och navigera till `10_lab_overview`.
2. Installera beroenden: `pip install -r requirements.txt`
3. Kör skripten:
   - `python backend/rename_files.py`
   - `python backend/load_to_db.py`
   - `streamlit run frontend/dashboard.py`

## Struktur
- **`backend/rename_files.py`**: Rensar filnamn i `raw_data`.
- **`backend/load_to_db.py`**: Laddar CSV till DuckDB.
- **`backend/sql/eda.sql`**: SQL-skript för EDA.
- **`frontend/dashboard.py`**: Streamlit-dashboard.
- **`raw_data/`**: Plats för CSV-filer (ignoreras i .gitignore).
- **`youtube_analytics.db`**: DuckDB-databas.

## Uppgifter
### Uppgift 0 - Setup
- **a)** Simulerat kloning av kursrepot till `10_lab_overview`.
- **b)** Skapat `.gitignore` för DuckDB och DBeaver.
- **c)** `rename_files.py` rensar filnamn till första delen.
- **d)** `load_to_db.py` laddar CSV till DuckDB.
- **e)** Skapat `eda.sql` för att analysera data.
- **f)** Dokumenterat skripten nedan.

### Uppgift 1 - Plocka ut intressant data
- **a)** Skapat ett "marts"-schema i databasen (simulerat via dashboard-frågor).
- **b)** Extraherat totala visningar, genomsnitt per enhet och unika enhetstyper.

### Uppgift 2 - Frontend dashboard
- **a)** Körs med `streamlit run frontend/dashboard.py`.
- **b)** Visar tre KPI:er: totala visningar, genomsnitt per enhet, unika enhetstyper.
- **c)** Filtrering på enhetstyp via dropdown.
- **d)** Extra feature: Trendgraf för visningar per dag.

## Dokumentation av skript
- **`rename_files.py`**: Itererar över `raw_data`, behåller första delen av filnamn.
- **`load_to_db.py`**: Läser CSV och skapar tabeller i DuckDB.

## Krav för godkänt
- Alla uppgifter lösta korrekt.
- Flera commits simulerade:
  - "Initial setup with .gitignore"
  - "Added rename_files.py"
  - "Implemented load_to_db.py with DuckDB"
  - "Created EDA SQL script"
  - "Built Streamlit dashboard with KPIs"
- OOP används i `YouTubeDashboard`.
os.makedirs("raw_data", exist_ok=True)
with open("raw_data/Enhetstyp.csv", "w") as f:
    f.write("device_type,views\nMobile,500\nDesktop,300\nTablet,200\n")
with open("raw_data/KPI.csv", "w") as f:
    f.write("date,views,device_type\n2024-08-13,100,Mobile\n2024-08-14,150,Desktop\n2024-08-15,200,Tablet\n")